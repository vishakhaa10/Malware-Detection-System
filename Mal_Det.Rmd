---
title: "Mal_Det"
author: "sanjeev.N.S"
date: "2024-04-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Load necessary libraries
library(dplyr)
library(caret)
library(xgboost)
```

```{r}
mydata<-read.csv("C:\\Users\\SRIDHAR\\Downloads\\MalwareSamples10000.csv")
df = subset(mydata, select = -c(specimenId) )
```

```{r}
# Perform basic data exploration
head(df)
summary(df)
```

```{r}
# Preprocessing
# One-hot encoding for the 'isMalware' column
df <- mutate(df, isMalware = ifelse(isMalware == "Yes", 1, 0))
print(head(df$isMalware,15))
```

```{r}
###To replace Nan value with 0
ind <- rowSums(is.na(df)) == ncol(df)
ind
```


```{r}
########Process the data for machine learning algorithms
procdata <- data.frame(as.numeric(as.factor(df$hasExe)),
                       as.numeric(as.factor(df$hasZip)),
                       as.numeric(as.factor(df$hasPDF)),
                       as.numeric(as.factor(df$hasDoc)),
                       as.numeric(as.factor(df$hasUnknown)),
                       as.numeric(as.factor(df$hasURL)),
                       as.numeric(df$urlCount),
                       as.numeric(df$totalEmailSizeBytes),
                       as.numeric(as.factor(df$senderDomainSuffix)),
                       as.numeric(df$headerCount),
                       as.numeric(df$isMalware))
                       
colnames(procdata) <- c("hasExe", "hasZip", "hasPDF", "hasDoc","hasUnknown","hasURL","urlCount","totalEmailSizeBytes" ,"senderDomainSuffix","headerCount","isMalware")

#procdata$isMalware <- ifelse(procdata$isMalware == "Yes", 1, 0)
procdata$isMalware <- factor(procdata$isMalware, levels = c(0, 1))
summary(procdata)
```

```{r}

cnt<- c(summary(procdata$isMalware)[[1]],summary(procdata$isMalware)[[2]])
print(cnt)
```

```{r}
# Plotting
# Bar plot of malware distribution
ggplot(procdata, aes(x = isMalware, fill = isMalware)) +
  geom_bar() + coord_cartesian(ylim=c(4500,5100)) + 
  labs(title = "Distribution of Malware Cases", x = "Is Malware", y = "Count")
```

```{r}
# Scatter plot of email size vs. header count colored by malware status
ggplot(procdata, aes(x = headerCount, y = totalEmailSizeBytes, color = isMalware)) +
  geom_point(size = 4) +
  labs(title = "Email Size vs Header Count by Malware Status", x = "Header Count", y = "Total Email Size (Bytes)")
```

```{r}
# Split the data into training and testing sets (80% training, 20% testing)
set.seed(123)  # for reproducibility
train_index <- createDataPartition(procdata$isMalware, p = 0.8, list = FALSE)
train_data <- procdata[train_index, ]
test_data <- procdata[-train_index, ]
```


*QDA model
```{r}
# Load necessary library
library(MASS)

# Train QDA model
qda_model <- qda(isMalware ~ ., data = train_data)

# Make predictions on the testing data
predictions_qda <- predict(qda_model, newdata = test_data)

# Extract predicted classes
predictions_qda_class <- predictions_qda$class
#predictions_qda_class <- as.factor(predictions_qda_class)
# Evaluate the QDA model using confusion matrix
confusionMatrix(predictions_qda_class, as.factor(test_data$isMalware))

```

*GPC(Gaussian ) model
```{r}
library(kernlab)
# Train GPC model
gpc_model <- ksvm(isMalware ~ ., data = train_data, type = "C-svc", kernel = "rbfdot")

# Make predictions on the testing data
predictions_gpc <- predict(gpc_model, test_data, type = "response")

# Convert probabilities to binary predictions (0 or 1)
predictions_gpc_binary <- ifelse(predictions_gpc > 0.5, 1, 0)
#predictions_gpc_binary <-as.factor(predictions_gpc_binary)

# Evaluate the GPC model using confusion matrix
confusionMatrix(predictions_gpc, test_data$isMalware)


```


*Naive bayes
```{r}
library(naivebayes)
train_data$isMalware <- as.factor(train_data$isMalware)
# Model 5: Naive Bayes
nb_model <- naive_bayes(isMalware ~ ., data = train_data)
# Model 5: Naive Bayes
predictions_nb <- predict(nb_model, newdata = test_data)
```

```{r}
confusionMatrix(predictions_nb, as.factor(test_data$isMalware))
```


```{r}
# Combine models using gradient boosting (XGBoost)
combined_predictions <- cbind(predictions_qda_class, predictions_gpc, predictions_nb)
xgb_model <- xgboost(data = as.matrix(combined_predictions), label = test_data$isMalware,nrounds = 100,objective = "reg:squarederror")

# Make predictions using the ensemble model
predictions_ensemble <- predict(xgb_model, as.matrix(combined_predictions))

# Convert probabilities to binary predictions (0 or 1)
predictions_ensemble_binary <- ifelse(predictions_ensemble > 1.5, 1, 0)

# Evaluate the ensemble model
confusionMatrix(as.factor(predictions_ensemble_binary), test_data$isMalware)

```




##testing

```{r}
#Testing
testing<-read.csv("C:\\Users\\SRIDHAR\\Downloads\\EmailSamples50000(2).csv")
dat = subset(testing, select = -c(specimenId) )
#To replace Nan value with 0
ind <- rowSums(is.na(dat)) == ncol(dat)
ind
```

```{r}
# Preprocessing
# One-hot encoding for the 'isMalware' column
dat <- mutate(dat, isMalware = ifelse(isMalware == "Yes", 1, 0))
```

```{r}
set.seed(456)
#Process the data for machine learning algorithms predictions
proctest <- data.frame(as.numeric(as.factor(dat$hasExe)),
                       as.numeric(as.factor(dat$hasZip)),
                       as.numeric(as.factor(dat$hasPDF)),
                       as.numeric(as.factor(dat$hasDoc)),
                       as.numeric(as.factor(dat$hasUnknown)),
                       as.numeric(as.factor(dat$hasURL)),
                       as.numeric(dat$urlCount),
                       as.numeric(dat$totalEmailSizeBytes),
                       as.numeric(as.factor(dat$senderDomainSuffix)),
                       as.numeric(dat$headerCount),
                       dat$isMalware)

colnames(proctest) <- c("hasExe", "hasZip", "hasPDF", "hasDoc", "hasUnknown","hasURL","urlCount","totalEmailSizeBytes" ,"senderDomainSuffix","headerCount","isMalware")

proctest$isMalware <- as.factor(proctest$isMalware)
#proctest$isMalware <- factor(proctest$isMalware, levels = c(0, 1))
```
```{r}
#QDA model
predictions_qda <- predict(qda_model, newdata = proctest)
predictions_qda_class <- predictions_qda$class
cf1 <- confusionMatrix(as.factor(predictions_qda_class), as.factor(proctest$isMalware))
```

```{r}
# Assuming 'cf' is the confusion matrix object
# You may need to replace 'cf' with the name of your confusion matrix object

# True positive (TP)
TP <- cf1$table[2, 2]

# False positive (FP)
FP <- cf1$table[1, 2]

# True negative (TN)
TN <- cf1$table[1, 1]

# False negative (FN)
FN <- cf1$table[2, 1]

# Accuracy
#accuracy <- sum(diag(cf1)) / sum(cf1)

# Precision
precision <- TP / (TP + FP)

# Recall (Sensitivity)
recall <- TP / (TP + FN)

# Specificity
specificity <- TN / (TN + FP)

# Sensitivity (True Positive Rate)
sensitivity <- recall

# Specificity (True Negative Rate)
specificity <- TN / (TN + FP)

# False Positive Rate
FPR <- FP / (FP + TN)

# False Negative Rate
FNR <- FN / (FN + TP)

# True Positive Rate (Recall)
TPR <- TP / (TP + FN)

# False Positive Rate
FPR <- FP / (FP + TN)

# True Negative Rate
TNR <- TN / (TN + FP)

# Print the calculated metrics
#cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall (Sensitivity):", recall, "\n")
cat("Specificity:", specificity, "\n")
cat("Sensitivity (True Positive Rate):", sensitivity, "\n")
cat("Specificity (True Negative Rate):", specificity, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("False Negative Rate:", FNR, "\n")
cat("True Positive Rate (Recall):", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("True Negative Rate:", TNR, "\n")

```


```{r}
#GPC

predictions_gpc <- predict(gpc_model, proctest, type = "response")
#predictions_gpc_binary <- ifelse(predictions_gpc > 0.5, 1, 0)
#predictions_gpc_binary <- as.factor(predictions_gpc_binary)
cf2 <- confusionMatrix(as.factor(predictions_qda_class), as.factor(proctest$isMalware))
```

```{r}
# Assuming 'cf' is the confusion matrix object
# You may need to replace 'cf' with the name of your confusion matrix object

# True positive (TP)
TP <- cf2$table[2, 2]

# False positive (FP)
FP <- cf2$table[1, 2]

# True negative (TN)
TN <- cf2$table[1, 1]

# False negative (FN)
FN <- cf2$table[2, 1]

# Accuracy
#accuracy <- sum(diag(cf1)) / sum(cf1)

# Precision
precision <- TP / (TP + FP)

# Recall (Sensitivity)
recall <- TP / (TP + FN)

# Specificity
specificity <- TN / (TN + FP)

# Sensitivity (True Positive Rate)
sensitivity <- recall

# Specificity (True Negative Rate)
specificity <- TN / (TN + FP)

# False Positive Rate
FPR <- FP / (FP + TN)

# False Negative Rate
FNR <- FN / (FN + TP)

# True Positive Rate (Recall)
TPR <- TP / (TP + FN)

# False Positive Rate
FPR <- FP / (FP + TN)

# True Negative Rate
TNR <- TN / (TN + FP)

# Print the calculated metrics
#cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall (Sensitivity):", recall, "\n")
cat("Specificity:", specificity, "\n")
cat("Sensitivity (True Positive Rate):", sensitivity, "\n")
cat("Specificity (True Negative Rate):", specificity, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("False Negative Rate:", FNR, "\n")
cat("True Positive Rate (Recall):", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("True Negative Rate:", TNR, "\n")

```

```{r}
#naive bayes
predictions_nb <- predict(nb_model, newdata = proctest)
cf3 <- confusionMatrix(as.factor(predictions_nb), as.factor(proctest$isMalware))
```

```{r}
# Assuming 'cf' is the confusion matrix object
# You may need to replace 'cf' with the name of your confusion matrix object

# True positive (TP)
TP <- cf3$table[2, 2]

# False positive (FP)
FP <- cf3$table[1, 2]

# True negative (TN)
TN <- cf3$table[1, 1]

# False negative (FN)
FN <- cf3$table[2, 1]

# Accuracy
#accuracy <- sum(diag(cf1)) / sum(cf1)

# Precision
precision <- TP / (TP + FP)

# Recall (Sensitivity)
recall <- TP / (TP + FN)

# Specificity
specificity <- TN / (TN + FP)

# Sensitivity (True Positive Rate)
sensitivity <- recall

# Specificity (True Negative Rate)
specificity <- TN / (TN + FP)

# False Positive Rate
FPR <- FP / (FP + TN)

# False Negative Rate
FNR <- FN / (FN + TP)

# True Positive Rate (Recall)
TPR <- TP / (TP + FN)

# False Positive Rate
FPR <- FP / (FP + TN)

# True Negative Rate
TNR <- TN / (TN + FP)

# Print the calculated metrics
#cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall (Sensitivity):", recall, "\n")
cat("Specificity:", specificity, "\n")
cat("Sensitivity (True Positive Rate):", sensitivity, "\n")
cat("Specificity (True Negative Rate):", specificity, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("False Negative Rate:", FNR, "\n")
cat("True Positive Rate (Recall):", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("True Negative Rate:", TNR, "\n")

```

```{r}
#ensemble learning
combined_predictions <- cbind(predictions_qda_class, predictions_gpc, predictions_nb)
xgb_model <- xgboost(data = as.matrix(combined_predictions), label = proctest$isMalware,nrounds = 100)
predictions_ensemble <- predict(xgb_model, as.matrix(combined_predictions))
predictions_ensemble_binary <- ifelse(predictions_ensemble > 1.5, 1, 0)

# Evaluate the ensemble model
cf <- confusionMatrix(as.factor(predictions_ensemble_binary), as.factor(proctest$isMalware))
cf
```

```{r}
# Assuming 'cf' is the confusion matrix object
# You may need to replace 'cf' with the name of your confusion matrix object

# True positive (TP)
TP <- cf$table[2, 2]

# False positive (FP)
FP <- cf$table[1, 2]

# True negative (TN)
TN <- cf$table[1, 1]

# False negative (FN)
FN <- cf$table[2, 1]

# Accuracy
#accuracy <- sum(diag(cf)) / sum(cf)

# Precision
precision <- TP / (TP + FP)

# Recall (Sensitivity)
recall <- TP / (TP + FN)

# Specificity
specificity <- TN / (TN + FP)

# Sensitivity (True Positive Rate)
sensitivity <- recall

# Specificity (True Negative Rate)
specificity <- TN / (TN + FP)

# False Positive Rate
FPR <- FP / (FP + TN)

# False Negative Rate
FNR <- FN / (FN + TP)

# True Positive Rate (Recall)
TPR <- TP / (TP + FN)

# False Positive Rate
FPR <- FP / (FP + TN)

# True Negative Rate
TNR <- TN / (TN + FP)

# Print the calculated metrics
#cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall (Sensitivity):", recall, "\n")
cat("Specificity:", specificity, "\n")
cat("Sensitivity (True Positive Rate):", sensitivity, "\n")
cat("Specificity (True Negative Rate):", specificity, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("False Negative Rate:", FNR, "\n")
cat("True Positive Rate (Recall):", TPR, "\n")
cat("False Positive Rate:", FPR, "\n")
cat("True Negative Rate:", TNR, "\n")

```


```{r}

# Combine the accuracies into a data frame
accuracy_data <- data.frame(
  Model = c("QDA", "GPC", "Naive Bayes", "Ensemble"),
  Accuracy = c(cf1$overall[[1]],cf2$overall[[1]],cf3$overall[[1]],cf$overall[[1]]))

# Load the ggplot2 library for plotting
library(ggplot2)

# Create the bar chart
ggplot_object <- ggplot(accuracy_data, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity", width = 0.7) +
  ylim(0, 0.99) +
  geom_text(aes(label = round(Accuracy, 4)),
            vjust = -0.3, 
            color = "black", 
            size = 3.5)+
  labs(title = "Comparison of Model Accuracies", x = "Model", y = "Accuracy") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")  # Colors the bars; optional

# Display the plot
print(ggplot_object)
```

